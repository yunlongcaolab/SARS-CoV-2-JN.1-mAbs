{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "147cedeb-698e-4839-9de3-1058113a998f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mAbs: 2688\n",
      "Number of significant sites: 71\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dms_scores = pd.read_csv(\"../data/DMS/antibody/dms_antibodies_XBB15_JN1_agg.csv\")\n",
    "\n",
    "# We will use \"site scores\" as antibody features\n",
    "# site_mat should be normalized by sum = 1 for each antibody\n",
    "site_mat = dms_scores.groupby(['antibody','site']).sum().reset_index().assign(\n",
    "    mut_escape = lambda x: x.groupby('antibody')['mut_escape'].transform(lambda y: y/y.sum())\n",
    ")\n",
    "\n",
    "use_abs = set(pd.unique(site_mat['antibody']))\n",
    "print(\"Number of mAbs:\", len(use_abs))\n",
    "\n",
    "# To integrate the results from JN.1 and XBB.1.5 DMS, scores on the key deletion V483del is removed during the analysis\n",
    "exclude_sites = [483]\n",
    "\n",
    "# selected significant sites as features\n",
    "# (normalized site score > 0.1 for at least 0.2% mAbs in the dataset)\n",
    "use_sites = site_mat.query(\"mut_escape > 0.1\").groupby('site')['antibody'].count()\n",
    "use_sites = use_sites[use_sites >= 0.002*len(use_abs)].index.to_list()\n",
    "print(\"Number of significant sites:\", len(np.setdiff1d(use_sites, exclude_sites)))\n",
    "\n",
    "site_mat = site_mat.query('site in @use_sites and site not in @exclude_sites')\n",
    "# normalize again\n",
    "site_mat = site_mat.assign(\n",
    "    value = lambda x: x.groupby(\n",
    "    ['antibody'])['mut_escape'].transform(lambda x: x/x.sum())\n",
    ").pivot(columns='site',values=\"mut_escape\",index=\"antibody\").fillna(0.0)\n",
    "site_mat.index.name = 'id'\n",
    "site_mat.to_csv(\"../data/DMS/antibody/_site_mat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10c51428-d995-44c4-a3bc-1098a025eb91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2688 2688\n"
     ]
    }
   ],
   "source": [
    "# Load some useful information of the mAbs\n",
    "mAb_info = pd.read_csv(\"../data/_mAb_info_clean.csv\").query(\"id in @use_abs\")\n",
    "print(len(mAb_info), len(use_abs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce7bffe9-9738-4650-9493-208f323945e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XBB.1.5 library DMS mAbs: 2286\n",
      "JN.1 library DMS mAbs: 766\n",
      "Assayed in both libraries: 364\n",
      "XBB.1.5 DMS mAbs by source:\n",
      "                                 id\n",
      "source                             \n",
      "BA.1 + BA.5/BF.7 infection       97\n",
      "BA.1 BTI                         52\n",
      "BA.1 BTI + BA.5/BF.7 infection  161\n",
      "BA.2 + BA.5/BF.7 infection      109\n",
      "BA.2 BTI                         57\n",
      "BA.2 BTI + BA.5/BF.7 infection  135\n",
      "BA.5 + JN.1 infection            25\n",
      "BA.5 + XBB infection            293\n",
      "BA.5 BTI                         78\n",
      "BA.5 BTI + HK.3 infection       274\n",
      "BA.5 BTI + JN.1 infection        58\n",
      "BA.5 BTI + XBB infection        297\n",
      "BF.7 BTI                         53\n",
      "SARS                              1\n",
      "SARS exposure                     6\n",
      "WT convalescents                 10\n",
      "WT-phage display                  1\n",
      "XBB BTI                         264\n",
      "XBB infection                   270\n",
      "long-term BA.1 BTI               16\n",
      "long-term BA.5 BTI               23\n",
      "long-term BA.5 infection          6\n",
      "JN.1 DMS mAbs by source:\n",
      "                                 id\n",
      "source                             \n",
      "BA.1 + BA.5/BF.7 infection        1\n",
      "BA.1 BTI + BA.5/BF.7 infection    3\n",
      "BA.2 BTI + BA.5/BF.7 infection    3\n",
      "BA.5 + JN.1 infection           190\n",
      "BA.5 + XBB infection             64\n",
      "BA.5 BTI + HK.3 infection       106\n",
      "BA.5 BTI + JN.1 infection       285\n",
      "BA.5 BTI + XBB infection         79\n",
      "SARS exposure                     4\n",
      "WT convalescents                  2\n",
      "XBB BTI                          13\n",
      "XBB infection                    10\n",
      "long-term BA.5 BTI                3\n",
      "long-term BA.5 infection          1\n"
     ]
    }
   ],
   "source": [
    "# statistics\n",
    "XBB15_mAbs = pd.unique(dms_scores.query('antigen == \"XBB.1.5_RBD\"')['antibody'])\n",
    "JN1_mAbs = pd.unique(dms_scores.query('antigen == \"JN.1_RBD\"')['antibody'])\n",
    "mAbs_both = np.intersect1d(XBB15_mAbs, JN1_mAbs)\n",
    "print(f\"XBB.1.5 library DMS mAbs: {len(XBB15_mAbs)}\")\n",
    "print(f\"JN.1 library DMS mAbs: {len(JN1_mAbs)}\")\n",
    "print(f\"Assayed in both libraries: {len(mAbs_both)}\")\n",
    "\n",
    "print(\"XBB.1.5 DMS mAbs by source:\")\n",
    "print(mAb_info[['id','source']].query('id in @XBB15_mAbs').groupby('source').count())\n",
    "\n",
    "print(\"JN.1 DMS mAbs by source:\")\n",
    "print(mAb_info[['id','source']].query('id in @JN1_mAbs').groupby('source').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "825361e3-62ff-4e9b-9e63-67c109ed4a36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from multiprocessing import Pool\n",
    "def calc_sqrt_JSD(pair):\n",
    "    array, idx = pair\n",
    "    return ([idx, [\n",
    "        np.sqrt(jensenshannon(array[idx, :], array[j, :])) for j in range(array.shape[0])\n",
    "    ]])\n",
    "\n",
    "site_mat_arr = site_mat.to_numpy()\n",
    "n_threads = 32\n",
    "with Pool(n_threads) as pool:\n",
    "    divergences = pool.map(calc_sqrt_JSD, [[site_mat_arr, x] for x in range(len(site_mat.index))])\n",
    "    \n",
    "dist = np.empty((len(site_mat), len(site_mat)))\n",
    "for i, x in divergences:\n",
    "    dist[i,:] = x\n",
    "\n",
    "dist = pd.DataFrame(dist, index=site_mat.index.to_list(), columns=site_mat.index.to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c8833cc-2522-4aa6-a6ce-cf1fabe6c221",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a Graph for leiden clustering\n",
    "import leidenalg as la\n",
    "import igraph as ig\n",
    "\n",
    "class DMSProfileGraph(ig.Graph):\n",
    "    def __init__(self, edges_df):\n",
    "        nodes = pd.unique(edges_df['index'])\n",
    "        self.sample2node = {}\n",
    "        self.node2sample = {}\n",
    "        edges_node = set()\n",
    "        \n",
    "        for i in range(len(nodes)):\n",
    "            self.node2sample[i] = nodes[i]\n",
    "            self.sample2node[nodes[i]] = i\n",
    "        \n",
    "        for u, v, w in edges_df.to_numpy():\n",
    "            _u = self.sample2node[u]\n",
    "            _v = self.sample2node[v]\n",
    "            edges_node.add((min(_u,_v), max(_u,_v)))\n",
    "            \n",
    "        super().__init__(n = len(nodes), edges = edges_node)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sample2node)\n",
    "\n",
    "import logomaker\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "def site_to_pos(sites, split='+'):\n",
    "    sites = sorted(sites, key=lambda x: [int(y) for y in x.split(split)])\n",
    "    site2pos = {}\n",
    "    for i in range(len(sites)):\n",
    "        site2pos[sites[i]] = i\n",
    "    \n",
    "    return sites, site2pos\n",
    "\n",
    "def plot_res_logo(res, prefix, by='name', site_thres=0.1, width=26, shownames={}, num_per_page = 10, force_plot_sites = None, force_ylim = None, highlight_res = {}):\n",
    "    rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "    res[\"site\"] = res[\"site\"].astype(str)\n",
    "    flat_res = res.rename(columns={by:'antibody'}).pivot(index=['antibody', 'site'], columns='mutation', values='mut_escape').fillna(0)\n",
    "    sites_total_score = flat_res.sum(axis=1)\n",
    "\n",
    "    strong_sites = list(pd.unique(sites_total_score[sites_total_score > site_thres].reset_index()['site']))\n",
    "    plot_sites = strong_sites\n",
    "    \n",
    "    if force_plot_sites is not None:\n",
    "        plot_sites = force_plot_sites\n",
    "    \n",
    "    flat_res = flat_res.query('site in @plot_sites')\n",
    "    Abs = flat_res.index.get_level_values('antibody').unique()\n",
    "    Npages = len(Abs) // num_per_page + 1\n",
    "    \n",
    "    plot_sites, site2pos = site_to_pos(plot_sites)\n",
    "    \n",
    "    with PdfPages(prefix+'_aa_logo.pdf') as pdf:\n",
    "        for p in range(Npages):\n",
    "            Abs_p = Abs[p*10:min(len(Abs),(p+1)*10)]\n",
    "            fig = plt.figure(figsize=(width,len(Abs_p)*4.6)).subplots_adjust(wspace=0.2,hspace=0.5)\n",
    "\n",
    "            for i in range(len(Abs_p)):\n",
    "                ab = Abs_p[i]\n",
    "                _ = flat_res.loc[ab, :]\n",
    "                add_sites = np.setdiff1d(plot_sites, _.index)\n",
    "                for _site in add_sites:\n",
    "                    _.loc[_site,:] = 0.0\n",
    "                _.index = [site2pos[i] for i in _.index]\n",
    "                ax = plt.subplot(len(Abs_p), 1, i+1)\n",
    "                logo = logomaker.Logo(_,\n",
    "                               ax=ax, \n",
    "                               color_scheme='dmslogo_funcgroup', \n",
    "                               vpad=.1, \n",
    "                               width=.8)\n",
    "                logo.style_xticks(anchor=0, spacing=1, rotation=90, fontsize=16)\n",
    "                _max = np.sum(_.to_numpy(), axis=1).max()\n",
    "                ax.yaxis.set_tick_params(labelsize=20)\n",
    "                if force_ylim is not None:\n",
    "                    ax.set_ylim(0, force_ylim)\n",
    "                elif _max < 3:\n",
    "                    ax.set_ylim(0,3)\n",
    "                    ax.set_yticks(range(0, 3, 1))\n",
    "                elif _max < 5:\n",
    "                    ax.set_yticks(range(0, int(_max)+1, 1))\n",
    "                elif _max < 8:\n",
    "                    ax.set_yticks(range(0, int(_max)+1, 2))\n",
    "                else:\n",
    "                    ax.set_yticks(range(0, int(_max)+1, 3))\n",
    "\n",
    "                for color, sites in highlight_res.items():\n",
    "                    if ifsite in plot_sites:\n",
    "                        logo.highlight_position(p=site2pos[ifsite], color=color, alpha=.2)\n",
    "\n",
    "                ax.set_xticklabels(plot_sites)\n",
    "\n",
    "                if ab in shownames:\n",
    "                    ax.set_title(shownames[ab], fontsize=24, fontweight=\"bold\")\n",
    "                else:\n",
    "                    ax.set_title(ab, fontsize=24, fontweight=\"bold\")\n",
    "            pdf.savefig()\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "862f3e60-1299-4d94-a7b1-7034fd0dbf22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gshare/xielab/jianfc/miniforge3/envs/antibody/lib/python3.10/site-packages/umap/umap_.py:1857: UserWarning: using precomputed metric; inverse_transform will be unavailable\n",
      "  warn(\"using precomputed metric; inverse_transform will be unavailable\")\n",
      "/gshare/xielab/jianfc/miniforge3/envs/antibody/lib/python3.10/site-packages/umap/umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    }
   ],
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "n_neighbors = 12\n",
    "seed = 2024\n",
    "umap_params = {'n_neighbors': n_neighbors, 'min_dist':0.8, 'metric':'precomputed', 'random_state': seed}\n",
    "la_params = {'partition_type':la.RBConfigurationVertexPartition, 'resolution_parameter':2.0, 'seed': seed}\n",
    "\n",
    "edges = (\n",
    "    dist.reset_index().melt(id_vars=\"index\")\n",
    "        .query('index != variable').sort_values('value',ascending=True)\n",
    "        .groupby('index').head(n_neighbors)\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "knn_graph = DMSProfileGraph(edges_df = edges)\n",
    "\n",
    "partition = la.find_partition(knn_graph, **la_params).membership\n",
    "node_id = [knn_graph.sample2node[i] for i in dist.index]\n",
    "\n",
    "umap = pd.DataFrame(umap.UMAP(**umap_params).fit_transform(dist), index=site_mat.index, columns=['UMAP1', 'UMAP2']).assign(\n",
    "    cluster = ['C%02d'%partition[i] for i in node_id])\n",
    "\n",
    "# If the mAb_info contains a column as cluster annotation references\n",
    "\n",
    "# _ref = pd.read_csv(\"../data/DMS/antibody/_clustering.csv\")\n",
    "# umap = umap.merge(\n",
    "#     _ref[['id','new_group']], left_index=True, right_on='id', how='left')\n",
    "# contigmat = umap.groupby(['cluster','new_group'])['id'].count().reset_index().pivot(index='new_group', columns='cluster', values='id').fillna(0).astype(int)\n",
    "# contigmat.to_csv('../data/DMS/antibody/_group_vs_clusters.csv')\n",
    "# cluster_rename = contigmat.idxmax(axis=0).to_dict()\n",
    "\n",
    "# or annotate the clusters manually\n",
    "cluster_rename = {'C00': 'F3',\n",
    " 'C01': 'F1.2',\n",
    " 'C02': 'F3',\n",
    " 'C03': 'A1',\n",
    " 'C04': 'D3',\n",
    " 'C05': 'A2',\n",
    " 'C06': 'E3',\n",
    " 'C07': 'F3',\n",
    " 'C08': 'B',\n",
    " 'C09': 'A1',\n",
    " 'C10': 'E3',\n",
    " 'C11': 'E1/E2.1',\n",
    " 'C12': 'E2.2',\n",
    " 'C13': 'F1.1',\n",
    " 'C14': 'D4',\n",
    " 'C15': 'B',\n",
    " 'C16': 'E3',\n",
    " 'C17': 'D3',\n",
    " 'C18': 'D3',\n",
    " 'C19': 'F3',\n",
    " 'C20': 'E3',\n",
    " 'C21': 'D2'}\n",
    "\n",
    "src_groups = {\n",
    "    'XBB infection': \"XBB\",\n",
    "    'XBB BTI': \"XBB\",\n",
    "    'BA.5 + XBB infection': \"XBB\",\n",
    "    'BA.5 BTI + HK.3 infection': \"XBB\", \n",
    "    'BA.5 BTI + XBB infection': \"XBB\",\n",
    "    'BA.5 + JN.1 infection': \"JN.1\",\n",
    "    'BA.5 BTI + JN.1 infection': \"JN.1\",\n",
    "}\n",
    "\n",
    "umap = umap.merge(\n",
    "    mAb_info[['id', 'source','paper_reactivity','D614G_IC50', \n",
    "          'BA1_IC50', 'BA2_IC50','BA5_IC50', 'XBB1_5_IC50', 'HK3_1_IC50', 'JN1_IC50', \n",
    "          'JN1_F456L_IC50',\"JN1_R346T_F456L_IC50\",\"JN1_F456L_A475V_IC50\",\"KP3_IC50\", \"KP3_A475V_IC50\",\n",
    "          'v_gene_H', 'd_gene_H', 'j_gene_H', 'v_gene_L', 'j_gene_L', 'v_domain_shm_ratio_H','v_domain_shm_ratio_L','ACE2_competition'\n",
    "         ]],\n",
    "    left_on='id', right_on='id', how='outer',\n",
    ").assign(\n",
    "    new_group=lambda x:[cluster_rename[y] for y in x['cluster']],\n",
    "    XBB15_dms_assayed = lambda x:[(y in XBB15_mAbs) for y in x['id']],\n",
    "    JN1_dms_assayed = lambda x:[(y in JN1_mAbs) for y in x['id']],\n",
    "    # is_involved = lambda x:[(src in src_groups) for src in x['source']]\n",
    "    # src_group=lambda x:[src_groups[y] if y in src_groups else \"others\" for y in x['source']]\n",
    ")\n",
    "umap.set_index('id').to_csv(\"../data/DMS/antibody/_clustering.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4917f051-bb45-4eb7-b77f-d95dc073e5ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = umap.query('source in @src_groups')\n",
    "\n",
    "cnt = df.groupby(\"source\")['id'].count().to_dict()\n",
    "df.assign(src_cnt = lambda x: [cnt[y] for y in x['source']]).query('src_cnt > 100').assign(\n",
    "    contribution = lambda x: 1.0/x['src_cnt'],\n",
    ").groupby([\"source\", \"new_group\"])['contribution'].agg(['sum', 'count']).reset_index().assign(\n",
    "    label = lambda x: [y+' ('+str(round(cnt[y]))+')' for y in x['source']]).to_csv(\"../data/DMS/antibody/_group_stat.csv\", index=None)\n",
    "\n",
    "def ic50_weighting(x, low=0.001, high=1):\n",
    "    if pd.isna(x) or x > high:\n",
    "        return 0\n",
    "    if x < low:\n",
    "        return 1\n",
    "    res = -np.log10(x)\n",
    "    res_l = -np.log10(low)\n",
    "    res_h = -np.log10(high)\n",
    "    return 1.0-(res-res_l)/(res_h-res_l)\n",
    "\n",
    "\n",
    "neut_weighted_calc = []\n",
    "\n",
    "for use_neut in ['BA5_IC50', 'JN1_IC50', 'XBB1_5_IC50', 'HK3_1_IC50', 'JN1_R346T_F456L_IC50', 'KP3_IC50']:\n",
    "    datax = df.assign(\n",
    "        neut_weight = lambda x: [ic50_weighting(y) for y in x[use_neut]]\n",
    "    )\n",
    "\n",
    "    cnt = datax.groupby(\"source\")['neut_weight'].sum().to_dict()\n",
    "    cnt_orig = datax.groupby(\"source\")['neut_weight'].count().to_dict()\n",
    "    x = datax[['source', use_neut,'neut_weight', 'new_group']].groupby(['source', 'new_group'])['neut_weight'].sum().reset_index().assign(\n",
    "        cnt=lambda x: [cnt[y] for y in x['source']], cnt_orig=lambda x: [cnt_orig[y] for y in x['source']])\n",
    "    x['percentage'] = x['neut_weight'] * 100 / x['cnt']\n",
    "    x['effectiveness'] = x['neut_weight'] / x['cnt_orig']\n",
    "    \n",
    "    neut_weighted_calc.append(x.assign(\n",
    "        weight = use_neut, use_mAbs = 'all'\n",
    "    ))\n",
    "    \n",
    "    # split cross and specific\n",
    "    for spec in ['cross', 'specific']:\n",
    "        datax = df.query('paper_reactivity == @spec').assign(\n",
    "            neut_weight = lambda x: [ic50_weighting(y) for y in x[use_neut]]\n",
    "        )\n",
    "\n",
    "        cnt = datax.groupby(\"source\")['neut_weight'].sum().to_dict()\n",
    "        cnt_orig = datax.groupby(\"source\")['neut_weight'].count().to_dict()\n",
    "        x = datax[['source', use_neut,'neut_weight', 'new_group']].groupby(['source', 'new_group'])['neut_weight'].sum().reset_index().assign(\n",
    "            cnt=lambda x: [cnt[y] for y in x['source']], cnt_orig=lambda x: [cnt_orig[y] for y in x['source']])\n",
    "        x['percentage'] = x['neut_weight'] * 100 / x['cnt']\n",
    "        x['effectiveness'] = x['neut_weight'] / x['cnt_orig']\n",
    "\n",
    "        neut_weighted_calc.append(x.assign(\n",
    "            weight = use_neut, use_mAbs = spec\n",
    "        ))\n",
    "pd.concat(neut_weighted_calc).to_csv(f\"../data/DMS/antibody/_neut_weight_group_stat.csv\", index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af906a30-e33b-4c63-b2bf-6078e680f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_cnt = dms_scores[[\"antibody\", \"antigen\"]].drop_duplicates().groupby([\"antibody\"])['antigen'].count().reset_index().rename(columns={'antigen':'count'})\n",
    "\n",
    "dms_ag_avg = dms_scores.groupby([\"antibody\", \"site\", \"mutation\"])['mut_escape'].sum().reset_index().merge(\n",
    "        _cnt, on=\"antibody\").assign(mut_escape = lambda x: x['mut_escape'] / x['count']).drop(columns=['count'])\n",
    "\n",
    "dms_ag_avg.to_csv(\"../data/DMS/antibody/_XBB15_JN1_aggregate_dms_scores.csv\", index=None)\n",
    "\n",
    "dms_ag_avg = dms_ag_avg.merge(\n",
    "        umap[['new_group', 'source', 'cluster', 'id']], \n",
    "    left_on='antibody', right_on='id',how='left'\n",
    ").drop(columns=['id']).dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44c4e39d-a80f-4c37-a087-a608a9c77ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dms_scores_annotated = dms_scores.merge(umap[['id','source', 'new_group', 'paper_reactivity']], how='left', left_on='antibody', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c514617f-039e-4079-81d6-9cc9cfd69fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41454/2945337053.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  res[\"site\"] = res[\"site\"].astype(str)\n",
      "/tmp/ipykernel_41454/2945337053.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  res[\"site\"] = res[\"site\"].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# generate some logo plots using aggreagted XBB.1.5-JN.1 DMS scores\n",
    "cluster_cnt = umap.groupby(\"cluster\")['id'].count().to_dict()\n",
    "group_cnt = umap.groupby(\"new_group\")['id'].count().to_dict()\n",
    "\n",
    "cluster_mean = dms_ag_avg.groupby(\n",
    "    [\"site\",\"mutation\",\"cluster\"])['mut_escape'].sum().reset_index().assign(\n",
    "    mut_escape = lambda x: [x.loc[i, 'mut_escape']/cluster_cnt[x.loc[i, 'cluster']] for i in x.index]\n",
    ")\n",
    "group_mean = dms_ag_avg.groupby(\n",
    "    [\"site\",\"mutation\",\"new_group\"])['mut_escape'].sum().reset_index().assign(\n",
    "    mut_escape = lambda x: [x.loc[i, 'mut_escape']/group_cnt[x.loc[i, 'new_group']] for i in x.index]\n",
    ")\n",
    "\n",
    "group_mean.to_csv(\"../data/DMS/antibody/_scores_group_mean.csv\", index=None)\n",
    "cluster_mean.to_csv(\"../data/DMS/antibody/_scores_cluster_mean.csv\", index=None)\n",
    "\n",
    "group_mean.groupby(['new_group','site'])['mut_escape'].sum().reset_index().to_csv(\"../data/DMS/antibody/_site_scores_group_sum.csv\", index=None)\n",
    "\n",
    "plot_res_logo(group_mean.query('mut_escape > 0.03'), prefix=\"../plots/Extended/DMS/antibody/DMS_group_mean\", by=\"new_group\", site_thres=1, width=24)\n",
    "plot_res_logo(cluster_mean.query('mut_escape > 0.03'), prefix=\"../plots/Extended/DMS/antibody/DMS_cluster_mean\", by=\"cluster\", site_thres=1, width=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e86727af-d8e7-4f7a-b987-95313d2ab5cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41454/2945337053.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  res[\"site\"] = res[\"site\"].astype(str)\n",
      "/tmp/ipykernel_41454/2945337053.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  res[\"site\"] = res[\"site\"].astype(str)\n",
      "/tmp/ipykernel_41454/2945337053.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  res[\"site\"] = res[\"site\"].astype(str)\n"
     ]
    }
   ],
   "source": [
    "for g_group, y in [\n",
    "    (['A1', 'A2', 'F3', 'B'], 8),\n",
    "    (['D2', 'D3', 'D4'], 7),\n",
    "    (['E1/E2.1', 'E2.2', 'E3','F1.1', 'F1.2'], 10),\n",
    "]:\n",
    "    plot_res_logo(group_mean.query('mut_escape > 0.03 and new_group in @g_group'), \n",
    "                  prefix=f\"../plots/Extended/DMS/antibody/DMS_group_{'-'.join(g_group).replace('/','_')}_mean\", by=\"new_group\", site_thres=2, width=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "063b10c4-d921-42ab-8e24-f50ae805adf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split by epitope group. Average by source\n",
    "def calc_mAbs_by_source(res, group, src, group_col=\"new_group\", src_col=\"source\"):\n",
    "    _use_res = res.query(f\"{src_col} in @src and {group_col} in @group\")\n",
    "    _cnt = _use_res[[\"antibody\", src_col, group_col]].drop_duplicates().groupby([src_col, group_col])['antibody'].count().reset_index().rename(columns={'antibody':'count'})\n",
    "    return _use_res.groupby([src_col, group_col, \"site\", \"mutation\"])['mut_escape'].sum().reset_index().merge(\n",
    "        _cnt, on=[src_col, group_col]).assign(**{\n",
    "        'mut_escape': lambda x: x['mut_escape'] / x['count'],\n",
    "        src_col: lambda x: x[src_col]+' ('+x['count'].astype(str)+')'\n",
    "    })\n",
    "    return _use_res.query('mut_escape > 0.01')\n",
    "\n",
    "def plot_wrapper(df, g, use_src, file, src, out_dir = None):\n",
    "    df_avg = calc_mAbs_by_source(df, g, use_src, src_col=src)\n",
    "    if out_dir is not None:\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        df_avg.to_csv(os.path.join(out_dir, f\"{g.replace('/','_')}_{src}.csv\"), index=None)\n",
    "    plot_res_logo(df_avg, file, src, 0.5, 24)\n",
    "\n",
    "show_groups = pd.unique(umap['new_group'])\n",
    "show_src = list(src_groups.keys())\n",
    "# show_src = ['BA.5 BTI + XBB infection', 'BA.5 BTI + HK.3 infection', 'BA.5 BTI + JN.1 infection']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5137587-3ab5-416e-8643-30698e1bf598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"../plots/Extended/DMS/antibody/group_by_source\", exist_ok=True)\n",
    "\n",
    "with Pool(len(show_groups)) as pool:\n",
    "    pool.starmap(\n",
    "        plot_wrapper, [[\n",
    "            dms_ag_avg, g, show_src, \n",
    "            f\"../plots/Extended/DMS/antibody/group_by_source/Group_mean_{g.replace('/','_')}_by_source\", \"source\"\n",
    "        ] for g in show_groups]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd8e1193-4e40-405a-b2bd-d2bd11e0d732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with Pool(len(show_groups)) as pool:\n",
    "    pool.starmap(\n",
    "        plot_wrapper, [[\n",
    "            dms_scores_annotated.query(\"antigen == 'XBB.1.5_RBD'\"), g, show_src, \n",
    "            f\"../plots/Extended/DMS/antibody/group_by_source_XBB15/Group_mean_{g.replace('/','_')}_by_source\", \"source\"\n",
    "        ] for g in show_groups]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01da85c3-ff6c-4dd3-96a0-c35904ee5ef4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split by epitope group. Average by assayed antigen. only include mAbs that were assayed in both antigens\n",
    "\n",
    "os.makedirs(\"../plots/Extended/DMS/antibody/group_by_antigen\", exist_ok=True)\n",
    "\n",
    "_ = dms_scores_annotated.query(\"antibody in @mAbs_both\")\n",
    "with Pool(len(show_groups)) as pool:\n",
    "    pool.starmap(\n",
    "        plot_wrapper, [[\n",
    "            _, g, [\"XBB.1.5_RBD\", \"JN.1_RBD\"], \n",
    "            f\"../plots/Extended/DMS/antibody/group_by_antigen/Group_mean_{g.replace('/','_')}_by_antigen\", \"antigen\", \"../data/DMS/antibody/both_mAbs_grouped\"\n",
    "        ] for g in show_groups]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa9866e8-4c10-47d9-a722-7bd26424fa3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate the logo plot for each mAb\n",
    "# this is time-consuming\n",
    "\n",
    "groups = pd.unique(umap['new_group'])\n",
    "with Pool(len(groups)) as pool:\n",
    "    pool.starmap(plot_res_logo, [[\n",
    "        dms_scores_annotated.assign(\n",
    "            label = lambda x: x['antibody']+'('+x['antigen']+')',\n",
    "        ).query('new_group == @group and mut_escape > 0.01')[['site','mutation','mut_escape','label']], \n",
    "        f\"../plots/Extended/DMS/antibody/mAbs_dms_logo/mAb_dms_{group.replace('/','_')}\", \n",
    "        \"label\", \n",
    "        0.1, \n",
    "        30,\n",
    "    ] for group in groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a7a8a-a7f2-4cdb-8b5d-6924409dc742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "antibody",
   "language": "python",
   "name": "antibody"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
